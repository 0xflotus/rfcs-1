- Start Date: 2019-01-25
- RFC PR: (leave this empty)
- Prisma Issue: (leave this empty)

# Summary

Prisma has a powerful declarative migration system. The declarative nature however has inherent limitations such as providing information which is attached to the state transition from datamodel A to datamodel B.
Therefore this spec proposes to optionally open up the migration system with the help of migration files, which are being generated by the CLI and used as the source of truth for migrations in the future.

# Basic example

## The default case when starting out: No migration files and automatic migrations

```bash
prisma migrate
```

## Opting in to the migration files workflow

### Controlling migrations by hand

```bash
prisma migrate generate # creates a new file called `./migrate/MIGRATION_ID.ts`
prisma migrate apply # applies the migration in the database
```

### Skipping the editing of migration files and generate and apply in one step

```bash
prisma migrate
```

Note, that the semantics of `prisma migrate` slightly changes in the opted-in case. It additionally creates a migration file.
The behavior towards the database stays the same. It will still afterwards execute the migrations.

# Motivation

One of the biggest USPs of the Prisma migration system is the automatic transition between two states of datamodels.
While this approach is good enough for most of the use cases, it has a few disadvantages that we want to tackle with this spec.
The first problem is, that it's neither visible, which steps will be executed, nor is the user able to control these steps. Even if the migrations system is running as intended, this introduces an inherent trust issue as users don't have insights to how migrations are being executed.
Another limitation is, that when a breaking change is performed, such as creating a required field, users of the migrations system must be able to not only migrate the underlying database, but also migrate the data. This could e.g. mean adding default values for a new field for all the records that already exist in the database.

The biggest difference of this spec to the existing migrations system is, that instead of taking the `datamodel.prisma` file as the source of truth for the actual migration, it's just the source to create migration files. The source of truth for migrations are the migration scripts, which are saved in the migration files that are being generated by the CLI with the help of the migration engine.

# Detailed design

## Contents

- [Migration Table](#migration-table)
- [Up and Down](#up-and-down)
- [Modes of operation](#modes-of-operation)
- [Opting out of Prisma's migration system](#opting-out-of-prismas-migration-system)
- [Kinds of migrations](#kinds-of-migrations)
- [The migration loop](#the-migration-loop)
- [Keeping migrations in lockstep](#keeping-migrations-in-lock-step)
- [Commands](#commands)
- [Migration workflow](#migration-workflow)
- [Filenames & order of execution](#filenames-order-of-execution)
- [Scenarios](#scenarios)
- [Migration operations](#migration-operations)
- [Data migrations](#data-migrations)
- [Git-based workflows & conflict resolution](#git-based-workflows-conflict-resolution)
- [Migrations and Seeding](#migrations-and-seeding)
- [Rollbacks](#rollbacks)
- [Rerunning Migrations](#rerunning-migrations)
- [Low-level Database Access](#lowlevel-database-access)

## Migration Table

An important primitive which the Prisma migrations system is already using since its beginning, is the Prisma migration table. This is a table, which exists in the database that the migrations are being executed on. It consists of the history of migrations, that have already been executed and the currently running migrations.
These are the benefits of the migration table:

- By setting a lock on the table, it prevents two migrations from being executed at the same time
- It provides the migration history, which can be visualized and be useful to understand the evolution of the database schema
- It makes the safe execution of migration steps possible by ensuring that migration steps don't get executed twice.
- It ensures safe rollback behavior from migrations that fail. The migration and its steps are being stored here, so that all steps of a migration that have been executed until then can be undone.

### Handling multiple data sources

In the future, Prisma will support multiple data sources at the same time. You then can e.g. have a relation between a type `User` that is persisted in Postgres with a type `Post` that is persisted in MySQL.
If such a relation will be introduced, Prisma needs to resolve, which type comes from which data source. In order to do this, type names need to be globally unique. If that is the case, an ordinary `createRelation` migration operation can be used to perform that migration.

All migrations of a Prisma project are always stored in one migration table. The question is, where this table is being stored. This will be configurable through the prisma.yml file - a database can be marked as `primary`.

### Alternative storage options

In the version of Prisma of time of writing, the migration table is being stored in the same database as the data lives in. This doesn't have to be the case. Other possible options are the following:

- A central registry hosted by Prisma
- A file in the filesystem
- A file in S3
- A file in Google Cloud Storage
- A table in a different database, which is not being used for the actual data

## Up and Down

The avid reader will notice over the course of reading this spec, that we don't talk much about `up` and `down`, which is an integral part of many existing migration systems outside of Prisma.
Let's discuss, why `up` and `down` is **mostly** not needed in the Prisma migrations system and what the exceptions are.
In many migration systems as [Flyway](https://flywaydb.org/) or [Go Migrate](https://github.com/golang-migrate/migrate), users provide both the actual migration (aka `up`) and the reversal of the migration `down`.
Providing the reversal by hand is only needed, if the migration system can't deduce it automatically.
As the Prisma migration steps are defined on a higher abstraction level than the underlying database, Prisma is able to reverse every migration step that it provides.

There are exceptions to this, when Prisma is not able to deduce the reversal of a migration.
This is the case, when database-specific migrations such as `runSql` are being used. As arbitrary, complex SQL queries could be provided here, Prisma is not supporting the automatic reversal here. These, however shouldn't be necessary in the 99% use-case. The Prisma migrations system even exists for over 2 years without having these escape hatches.

## Modes of operation

### Opting-in and out of file-based migrations

To keep the current ease-of-use and minimal getting started experience, users will be able to start a new Prisma project without knowing the concept of migration files. Prisma will migrate from Datamodel A to Datamodel B with the same mechanics which power the migrations today - automatically determining the steps needed to perform the migration. As soon as the user hits the use-case to enter the migration files-based migration system, a simple `prisma migrate generate` will opt the user into the file-based migration system. From this point on, for each `prisma migrate` new files will be created into a folder called `./migrate`, relative to the `prisma.yml` file. To opt out of this workflow again, the user needs to delete the `./migrate` folder. From there on, the automatic migrations will be active again.

The difference between the automatic migrations and the file-based migrations is, that automatic migrations don't require to be [in lockstep with the migration table](#keeping-migrations-in-lockstep).

### Running Prisma as an embedded binary or as a server

Another dimension that plays a role for migrations is the mode in which Prisma runs. Prisma in the future will both be available as a binary that can be shipped as a library in specific languages and also a stand alone server, that can be deployed as a separate infrastructure component.
In which mode Prisma is running, has an influence on how the introspection flow looks like. The main relevant difference for migrations is, that the binary gets the datamodel that it takes as a basis to expose the GraphQL API injected on boot time. With this approach, the binary is representing a single-tenant approach, where per running binary only one datamodel can be exposed. In contrast to that, the server gets the datamodel injected in runtime and is able to serve multiple Prisma projects at the same time.
This means for migrations, that the pure database migration doesn't change, no matter if Prisma binary or Prisma server is being used to access the data.
The action of applying the datamodel however, differs. While the binary can just be restarted and will serve the new datamodel, the server needs to receive an api call to the migrations api to serve the new datamodel for a specific project. The command that is only needed by the server will be called `prisma apply-datamodel`.

### Dimensions

Taking these 2 dimensions of opting in or out of the file-based migrations and using a Prisma binary or server thereby represent 4 different modes in which the migration system can be operated.

## Opting out of Prisma's migration system

While Prisma provides a great migration experience, users still can always opt out of the Prisma migration system through running their own migrations, re-introspecting the database and generating a new Prisma Client based on the new datamodel, that results from the introspection. A legit use-case is, that an organization already has experience and proven workflows around an existing migrations system like Rails migrations. In order to incrementally adopt, the team can keep migrating the database using Rails, while generating the Prisma datamodel based on the state of the database schema.
Prisma then has a read-only relation to the database schema, while still being able to read and write data.

## The migration loop

The following diagram describes 3 different workflows around migrations:

```
┌──────────────────┐      ┌─────────────────┐
│  migration files ├─────▶│ migration table │
│                  │      └──────────┬──────┘
│┌────────────────┐│       ▲         │
││ migration-1.ts ││       │         │
│└────────────────┘│       │         │
│┌────────────────┐│       │         ▼
││ migration-2.ts ││       │   .───────────.
│└────────────────┘│       │  (  database   )
│┌────────────────┐│ ┌─────┘   `─────┬─────'
││ migration-3.ts ││ │               │
│└────────────────┘│ │               │
└──────────────────┘ │               │
          ▲          │               │
          │          │               ▼
┌─────────┴──────────┤       ┌───────────────┐
│  datamodel.prisma  │ ◀─────┤ introspection │
└────────────────────┘       └───────────────┘
```

### 1. Automatic migrations

When starting out with a fresh Prisma project, the user just describes the datamodel in a declarative manner into the `datamodel.prisma` file. When executing `prisma migrate`, this datamodel is being sent to the migration engine and the migration engine will calculate the necessary steps, if any, to migrate the underlying database to the new datamodel. This is how Prisma works as of the time of writing this spec.

### 2. File-based migrations

As soon, as a use-case is hit, where the Prisma user needs more control over the migrations system, as adding a required field, the user can opt in to the migrations system with `prisma migrate generate`.
In the case, that already 10 migrations are stored in the migration table, 10 migration files will be created.
Let's call the datamodel, that results from applying all migration files to an empty database the "migration file datamodel". If the migration file datamodel and the datamodel.prisma should differ, the migration engine now calculates the steps needed to get from the migration file datamodel to the datamodel.prisma, in other words, the diff.
This diff is now saved to a new migration file.
A single `prisma migrate` will now send all migrations to the migration engine.
The migrations engine can decide based on the current actual database schema and the migration table, which migrations should be executed.

### 3. Database introspection

A workflow that is not related to migrations per se, is the database introspection.
When starting out with a new Prisma project, there are two modes of operation:

1. Starting with an empty database and migrating the database to the datamodel declared in the `datamodel.prisma` file.
2. Starting with an existing database and creating a datamodel that maps to the existing database schema by using `prisma introspect`

As visible in the diagram above, the introspection now closes the loop when it comes to creating datamodels and migrating these to databases. It allows powerful workflows as incrementally adopting Prisma into an existing system while still keeping the existing migrations system. Prisma merely needs to re-introspect the database to obtain the new datamodel.

## Keeping migrations in lock step

> File-based migrations require the migrations to be in [lockstep](<https://en.wikipedia.org/wiki/Lockstep_(computing)>) with the steps saved in the migration table.

### Happy path

So if the local migration files have the following migrations:

```
Migration 1: Steps a,b,c
Migration 2: Steps d,e
Migration 3: Steps f,g
```

and the migration table the following entries

```
Migration 1: Steps a,b,c
Migration 2: Steps d,e
```

the migration engine will determine, that `Migration 3` is new and needs to be executed.
In contrast to that, the automatic migrations don't this syncing and just calculate the diff of the datamodel in the local filesystem and the migration table.

### Conflicts

This has the effect, that if the migration engine will reject any migration based on migration files, where the local migration files are out of sync with the remote migration table. This case can only occur, if the user manually changes the migration script.
Prisma will generate a useful error message stating the exact difference of the migrations.
The user can do 3 things from here:

1. Fix the migrations based on the feedback the server gave
2. Delete or rename the migrations folder, execute `prisma migrate generate` to get the migrations stored in the migration table
3. Use `prisma migrate apply --force-overwrite`, which overrides the whole migration history
4. Use `prisma migrate apply --ignore-migrations` to deploy based on the latest datamodel.

## Commands

### `prisma migrate`

This is the command users use when starting out with a fresh project.
In the beginning it won't create any migration files.
Later, when opted in to the file-based migrations, it will perform:
`prisma migrate` and `prisma migrate apply`, but not `prisma apply-datamodel` (as of now) for the server case.

What happens when `prisma migrate` is being executed:

```
┌─┬────────────┐  inferMigrationSteps(     ┌────────────────┐
│1│ prisma-cli │       datamodel)          │migration engine│
└─┴────────────┘──────────────────────────▶└────────────────┘

┌─┬────────────┐                           ┌────────────────┐                   ┌───────────────┐
│2│ prisma-cli │   startMigration(steps)   │migration engine│ checkSteps(steps) │migration table│
└─┴────────────┘──────────────────────────▶└────────────────┘──────────────────▶└───────────────┘

┌─┬────────────┐                           ┌────────────────┐                     .───────────.
│3│ prisma-cli │ applyNextMigrationStep()  │migration engine│  applyStep(step)   (  database   )
└─┴────────────┘──────────────────────────▶└────────────────┘──────────────────▶  `───────────'

┌─┬─────────────────────────────────────┐
│4│ Repeat 3 until all steps are done   │
└─┴────────────────────────────────── ◀─┘
```

### `prisma migrate generate`

Create migration files based on the steps that the migration engine calculates

### `prisma migrate generate --data-migration`

Create a template file to implement a data migration, which gets the Prisma Client injected.

### `prisma migrate apply`

Applies migrations in the database

### `prisma migrate apply --ignore-migration-files`

Migrates the database based on the latest datamodel and ignores local migration files.
This is only possible, if there is no migration table yet.
This command is in particular useful, when there are already a couple of hundred migrations and executing all of them from scratch would take a long time. If in a CI system you quickly want to boot a new server with this datamodel, this is the right command to use.
This command solves the same problems as squashing in migration systems like [Django](https://docs.djangoproject.com/en/2.1/topics/migrations/#migration-squashing). The mechanism to either migrate based on migration files or a snapshot (in our case the datamodel) is also used in [Active Record Migrations](https://edgeguides.rubyonrails.org/active_record_migrations.html).

Important to note: If the `execute` step is being used to seed necessary production data, this command cannot be used.
Therefore we recommend using the Prisma seeding system for these purposes.

### `prisma apply-datamodel`

Only update the API Schema, but not the underlying database

### `prisma dry-run`

Executes the migrations in a dry-run

### `prisma cleanup`

If migrations weren't successful, this can stop the migration running at the moment and rollback it's effects

### `prisma baseline`

This command introspects the database and add the introspection result to the Prisma Migration Table as a baseline for future deployments

## Migration Workflow

The new workflow how migrations should work with Prisma like this:

A user initiates a service with `prisma init` and ends up with a project folder like this:

```
.
├── datamodel.prisma
└── prisma.yml
```

and a `datamodel.prisma` file like this:

```graphql
type User {
  id: ID! @id
  email: String! @unique
  name: String!
}
```

The user then executes the `prisma migrate` command. The migrate command sends the datamodel to the migration engine, which then automatically migrates the database to the new datamodel.

Every time the user does changes in the datamodel.prisma, a simple `prisma migrate` updates the underlying database schema. This is how migrations with Prisma work as of the time of writing.

Let's say the developer using Prisma now runs the application in production and 100,000 users register for the app.
She finds out, that she wants to turn the single `name` field into a `firstName` and `lastName` field, which both ultimately should be required.

The following steps are how this situation can be solved with the old and new migrations system:

1. Introduce the `firstName` and `lastName` field for the `User` type, run `prisma migrate`.
2. Update the application code to use the `firstName` and `lastName` fields when creating new users.
3. Create and run a script, which migrates all existing users to the new structure.
4. Remove the `name` field from the datamodel, turn the `firstName` and `lastName` into required fields.
   Important to note here: The application must not point to the input types of `firstName` and `lastName` directly, as they would break now.

While creating and running the data migration script of step 3 is probably fairly easy to accomplish, a lot of effort with orchestration on top is needed to execute steps 1-4 in order in any other system as CI.
As soon as these data migrations are introduced multiple times, the situation gets even worse.
This is where the new Prisma file-based migrations come into play. To accomplish steps 1-4 with the file-based migrations, the following concrete steps are needed:

### 1. Add `firstName` and `lastName` to the `datamodel.prisma` file:

```graphql
type User {
  id: ID! @id
  email: String! @unique
  name: String!
  firstName: String
  lastName: String
}
```

### 2. Run `prisma migrate generate`. This creates 2 migration files: The first one including the migration we already ran, the second one representing the change of adding the new two fields:

`0001.ts`

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createModel({
    model: 'User',
    fields: {
      id: { name: 'id', type: 'ID' }
      name: { name: 'name', type: 'String' }
    }
  })
])
```

`0002.ts`

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.addField({
    model: 'User',
    name: 'firstName',
    type: 'String',
    isRequired: false,
  }),
  m.addField({
    model: 'User',
    name: 'lastName',
    type: 'String',
    isRequired: false,
  }),
])
```

### 3. Run `prisma migrate apply` to add the fields to the database schema

The migration engine will recognize, that `0001.ts` has been executed already and will execute the steps provided in `0002.ts`.

### 4. Update the application code to use the `firstName` and `lastName` fields when creating new users. (Step 2)

### 5. Run `prisma migrate generate --data-migration` to bootstrap the data migration script we will need split `name` into `firstName` and `lastName`.

The content of this file will look like this:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.execute(async ctx => {
    // access the client in a type-safe matter: ctx.client.
  }),
])
```

We now can implement our type-safe data migration:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.execute(async ({ client }) => {
    const batch = []
    for await (const user of client.users().$stream()) {
      // TODO: build more sophisticated name splitting
      const [firstName, lastName] = user.name.split(/\s+/)
      batch.push(
        client.updateUser({
          where: user.id,
          data: {
            name: null,
            firstName,
            lastName,
          },
        }),
      )
    }
    await client.batch(batch)
  }),
])
```

By running `prisma migrate apply`, the Prisma CLI will now run the data migration. The migration engine will add a _noop_ migration into the migration table to mark this migration as executed.

### 6. Now we can remove the `name` field and make our new fields required:

```graphql
type User {
  id: ID! @id
  email: String! @unique
  firstName: String!
  lastName: String!
}
```

By running `prisma migrate`, a new migration file will be created and the migration will immediately executed.
The filesystem will now look like this:

## Filenames & order of execution

Prisma would provide the opionation of calling migration files like this:

`VVVV_TIMESTAMP.ts`, where VVVV are 4 digits for the auto incrementing version and TIMESTAMP is a unix timestamp. The order in which Prisma reads the migration files is determined by a lexicographical ordering of the file names.

## Scenarios

### Scenario 1: Two compatible changes at the same time

Bob checks out the code locally and both Jen and Bob have a local version of Prisma running with their own database. Both Bob and Jen now perform a change to the datamodel, a local Migration file will be created and Jen pushes first. Bob doesn't pay too much attention what code Jen already pushed, just pulls and as he doesn't get any conflict, also pushes his code:

Jen's new `0002-1548425150000.ts`:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createField({
    model: 'User',
    name: 'address',
    type: 'String',
    migrationValue: '',
  }),
])
```

Bob's new `0002-1548425140000.ts`

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createField({
    model: 'User',
    name: 'age',
    type: 'Int',
    migrationValue: -1,
  }),
])
```

After the merge, the filesystem will look like this:

```
.
├── datamodel.prisma
├── migrate
│   ├── 0001_1548425145186.ts
│   ├── 0002-1548425140000.ts
│   └── 0002-1548425150000.ts
└── prisma.yml
```

The resulting datamodel will look like this:

```graphql
type User {
  id: ID! @id
  name: String!
  address: String!
  age: Int!
}
```

Prisma at this point should warn in a CI step, that two migrations have been created with the same version. But as these migrations are compatible, Prisma is able to merge them.

## Scenario 2: Two incompatible changes at the same time

Let's assume Jen now removes the `name` field from the `User` type, but Bob just wants to make it optional. This is a change that can't be solved automatically - we have a merge conflict.

The first barrier to prevent this from happening is a Git-based merge conflict in the `prisma.datamodel` file:

Jen's `datamodel.prisma` will look like this:

```graphql
type User {
  id: ID! @id
}
```

While Bob's `datamodel.prisma` will look like this:

```graphql
type User {
  id: ID @id
  name: String
}
```

The next barrier to catch this conflict is the actual Prisma migration system.

When the `prisma apply-migration` command is being executed in CI, it will read all migration files.

As soon as it will see the following two migrations, it will recognize a conflict:

Jen's migration file:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.deleteField({
    model: 'User',
    name: 'name',
  }),
])
```

Bob's migration file:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.updateField({
    model: 'User',
    name: 'name',
    type: 'String',
    isRequired: false,
  }),
])
```

Prisma would fail in this case and ask for manual resolution from the user.

## Scenario 3: Async Workflows, migrating data

In order to introduce a required field, that we need to initialize with proper data, we can provide a hook point for users to execute data transformations:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createField({
    model: 'User',
    name: 'address',
    type: 'String',
    isRequired: false,
  }),
  m.execute(async ctx => {
    for (const user of ctx.client.users().$stream()) {
      await ctx.client.updateUser(user.id, {
        address: 'some default address in the universe ' + Math.random(),
      })
    }
  }),
  m.updateField({
    model: 'User',
    name: 'address',
    type: 'String',
    isRequired: true,
  }),
])
```

The client could potentially even be typed with the new field. Note, that this requires a temporary endpoint, which already includes the new field, even if the migration is not yet done.

## Scenario 4: SQL / Database native code

To allow manipulating the underlying database directly, we provide a SQL interface:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [m.runSql(`CREATE TABLE X`, `DROP TABLE X`), m.runSql(`CREATE TABLE Y`)])
```

## Scenario 5: MongoDB access

The underlying MongoDB database could be manipulated like this:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.runMongo(
    [
      {
        createIndexes: 'mycollection',
        indexes: [
          {
            key: {
              username: 1,
              created: -1,
            },
            name: 'username_sort_by_asc_created',
            background: true,
          },
          {
            key: {
              email: 1,
            },
            name: 'unique_email',
            unique: true,
            background: true,
          },
        ],
      },
    ],
    [
      {
        dropIndexes: 'mycollection',
        index: 'username_sort_by_asc_created',
      },
      {
        dropIndexes: 'mycollection',
        index: 'unique_email',
      },
    ],
  ),
])
```

## Migration Operations

These are the possible operations, which the language specific migration definitions (like TypeScript or Go) will generate:

https://gist.github.com/mavilein/5b4a7407a4dfde9c070d26f276b0aa13

## Migrations and Seeding

https://edgeguides.rubyonrails.org/active_record_migrations.html#migrations-and-seed-data

- How seeding and deployment from snapshot emulate database forking

## Rerunning Migrations

- Undoing and rerunning specific migrations using migrations from scratch & force push

# Drawbacks

We could provide a completely free JavaScript API, without forcing the user to provide an array of operations. However, this wouldn't allow us to check migrations for validity upfront, so Prisma can't provide any guarantees and users would easily get into inconsistent states with their database.

## Streaming the changes for new items that are being created while making a field required

# Alternatives

# Adoption strategy

Users that are running the existing Prisma system will need to run `prisma migrate` instead of `prisma deploy`.
To opt into the file-based migrations, a single `prisma migrate generate` is sufficient.

# How we teach this

# Unresolved questions

## Should standalone pure data migrations be re-runnable?

## How will the datamodel be added to the migration scripts?

## When opted-in to the migrations system, should it be possible to skip `prisma migrate generate` with `prisma migrate` even if there are new changes?

## How do migrations in Go look like?

## How could migrations integrate with CI/CD and the Cloud?

## How could migrations integrate with Github Actions?

## How will the primary data source / source to save the migration table be configured?

## Should we introduce a "transform" hook?

See `name` -> `firstName` and `lastName` example.

## Should we allow different generic sources for migration files?

[Go Migrate](https://github.com/golang-migrate/migrate) not only allows migrations based on files in the filesystem, but also embedded binaries with go-bindata, Github Repositories, S3 Buckets, Google Cloud Storage

## How do we handle big migrations that need to scale over millions of table entries?

This would require a more sophisticated migration system, that uses data syncing with a Ghost table, as implemented by https://github.com/github/gh-ost.

A potential API to handle these "online" changes in a big production system could look like this:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createField({
    model: 'User',
    name: 'address',
    type: 'String',
    isRequired: true,
    migrationValue: '',
  }),
  m.runAsync({
    watch: {
      BeforeUserCreated: user => {
        const [firstName, lastName] = user.name.split(' ')
        user.firstName = firstName
        user.last = lastName
        return user
      },
    },
    run: async client => {
      for await (const user of client.users().$stream()) {
        await client.updateUser(user.id, 'BeforeUserCreated')
      }
    },
  }),
  m.updateField({
    model: 'User',
    name: 'address',
    type: 'String',
    isRequired: true,
  }),
])
```

## Should we block the API during migration?

Systems like Rails follow this approach. This would make migrations easier to reason about and prevent inconsistent data state. For a big production application this would however not be acceptable.

## Other

- [ ] How to generate a (type-safe) client for the run commands?
- [ ] Evaluate `dependsOn` concept
- [ ] Add option to prevent breaking changes

## Archive

```
.
├── datamodel.prisma
├── migrate
│   ├── 0001_1548425145186.ts
│   ├── 0002-1548425240000.ts
│   ├── 0003-1548425340000-data-migration.ts
│   └── 0004-1548425450000.ts
└── prisma.yml
```

The user then executes `prisma migrate`, which now creates a new migration file in the filesystem and applies that migration to the database:

```
.
├── datamodel.prisma
├── migrate
│   └── 0001_1548425145186.ts
└── prisma.yml
```

The content of `0001_1548425145186.ts` looks like this:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createModel({
    model: 'User',
    fields: {
      id: { name: 'id', type: 'ID' }
      name: { name: 'name', type: 'String' }
    }
  })
])
```

Let's call the Prisma user Jen. Jen now pushes the project to Github and shares the project with her colleague Bob. The migration is now checked into version control.
