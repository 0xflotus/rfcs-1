- Start Date: 2019-01-25
- RFC PR: (leave this empty)
- Prisma Issue: (leave this empty)

# Summary

This spec describes the new migrations system of Prisma. Users will be able to hook in to the migrations with migration scripts.

# Basic example

## The default case when starting out: No migration files and automatic migrations

```bash
prisma migrate
```

## Opting in to the migration files workflow

### Controlling migrations by hand

```bash
prisma migrate generate # creates a new file `./migrate/MIGRATION_ID.ts
prisma migrate apply # applies the migration in the database
```

### Skipping the "editing" of migration files and generate and apply in one step

```bash
prisma migrate
```

Note, that the semantics of `prisma migrate` slightly changes, but the behavior towards the database stays the same.
The only difference is, that when opted-in to the file-based migrations, `prisma migrate` will additionally create a migration file.

# Motivation

One of the biggest USPs of the Prisma migration system is the automatic transition between two states of datamodels.
While this approach is good enough for most of the use cases, it has a few disadvantages that we want to tackle with this spec.
The first problem is, that it's neither visible, which steps will be executed, nor is the user able to control these steps. Even if the migrations system is running as intended, this introduces an inherent trust issue as users don't have insights to how migrations are being executed.
When a breaking change is performed, such as creating a required field, users of the migrations system must be able to not only migrate the underlying database, but also migrate the data. This could e.g. mean adding default values for all the records that already exist in the database.

The biggest difference of this spec to the existing migrations system is, that instead of taking the `datamodel.prisma` file as the source of truth for the actual migration, it's just the source to create migration steps. The source of truth for migrations are the migration files that are being generated by the CLI.

# Detailed design

## Contents

- File-based migrations
- Binary vs Server
- 3 sources of truth: datamodel.prisma, migration files and the migration table
- Lock step over sources of truth
- What if the migration files and migration table is out of sync?
- Possible storage options for the migration table
- Migrations across multiple data sources
- All migration operations
- Migrations in Go
- Why we don't need squashing
- Deploying from snapshot vs migration files
- Rollbacks
- How does this integrate with CI/CD and the Cloud?
- How seeding and deployment from snapshot emulate database forking
- Possible integration with Github Actions

## Modes of operation

### Opting in and out of file-based migrations

To keep the current ease-of-use and minimal getting started experience, users will be able to start a new Prisma project without knowing the concept of migration files. Prisma will migrate from Datamodel A to Datamodel B with the same mechanics which power the migrations today - automatically determining the steps needed to perform the migration. As soon as the user hits the use-case to enter the migration files-based migration system, a simple `prisma migrate generate` will opt the user into the system. From this point on for each `prisma migrate` new files will be created into a folder called `./migrate`, relative to the `prisma.yml` file. To opt out of this workflow again, the user needs to delete the `./migrate` folder. From there on, the automatic migrations will be active again. While this is a big difference in user experience, the migrations engine, which will be implemented in Rust and shipped with Prisma, will just write the result of each migration into a migration table in the specific database that the Prisma service is connected to.

### Running Prisma as an embedded binary or as a server

Another dimension that plays a role for migrations is the mode in which Prisma runs. Prisma in the future will both be available as a binary that can be shipped as a library in specific languages and also a stand alone server, that can be deployed as a separate infrastructure component.
In which mode Prisma is running, has an influence on how the introspection flow looks like. The main relevant difference for migrations is, that the binary gets the datamodel that it takes as a basis to expose the GraphQL API injected on boot time. With this approach, the binary is representing a single-tenant approach, where per running binary only one datamodel can be exposed. In contrast to that, the server gets the datamodel injected in runtime and is able to serve multiple Prisma projects at the same time.
This means for migrations, that the pure database migration doesn't change, no matter if Prisma binary or Prisma server is being used to access the data.
The action of applying the datamodel however, differs. While the binary can just be restarted and will serve the new datamodel, the server needs to receive an api call to the migrations api to serve the new datamodel for a specific project. The command that is thereby only needed by the server will be called `prisma apply-datamodel`.

### Dimensions

Taking these 2 dimensions of opting in or out of the file-based migrations and using a Prisma binary or server thereby represent 4 different modes in which the migration system can be operated.

### Completely opting out of Prisma's migration system

While Prisma provides a great migration experience, users still can always opt out of the Prisma migration system through running their own migrations, re-introspecting the database and generating a new Prisma Client based on the new datamodel, that results from the introspection. A legit use-case is, that an organization already has experience and proven workflows around an existing migrations system like Rails migrations. In order to incrementally adopt, the team can keep migrating the database using Rails, while generating the Prisma datamodel based on the state of the database schema.
Prisma then has a read-only relation to the database schema, while still being able to read and write data.

## Commands

### `prisma migrate`

Executes `prisma migrate` and `prisma apply-migrations`, but not `prisma apply-datamodel` for the server case.

- `prisma migrate generate` Create migration files

- `prisma migrate apply` Applies migrations in the database

- `prisma apply-datamodel` Only upate the API Schema, but not the underlying database

- `prisma dry-run` Executes the migrations in a dry-run

- `prisma cleanup` If migrations weren't successful, this can stop the migration running at the moment and rollback it's effects

- `prisma baseline` This would introspect the database and add the introspection result to the Prisma Migration Table as a baseline for future deployments

The biggest question to answer for the migration system is this: Should users be able to opt in and opt out of the migration system or should it always be activated?

This proposal for now assumes, that the migration system is always opt in, as that is easier to reason about. However, we also present an alternative at the end of the design to provide opting in and out.

The new flow how migrations should work with Prisma is the following.

A user initiates a service with `prisma init` and ends up with a filesystem like this:

```
.
├── datamodel.prisma
└── prisma.yml
```

and a datamodel file like this:

```graphql
type User {
  id: ID! @id
  name: String!
}
```

The user then executes `prisma deploy`, which now creates a new migration file in the filesystem and applies that migration to the database:

```
.
├── datamodel.prisma
├── migrate
│   └── 0001_1548425145186.ts
└── prisma.yml
```

The content of `0001_1548425145186.ts` looks like this:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createModel({
    model: 'User',
    fields: {
      id: { name: 'id', type: 'ID' }
      name: { name: 'name', type: 'String' }
    }
  })
])
```

Let's call the Prisma user Jen. Jen now pushes the project to Github and shares the project with her colleague Bob. The migration is now checked into version control.

## Filenames / Order of execution

Prisma would provide the opionation of calling migration files like this:

`VVVV_TIMESTAMP.ts`, where VVVV are 4 digits for the auto incrementing version and TIMESTAMP is a unix timestamp. The order in which Prisma reads the migration files is determined by a lexicographical ordering of the file names.

## Scenario 1: Two compatible changes at the same time

Bob checks out the code locally and both Jen and Bob have a local version of Prisma running with their own database. Both Bob and Jen now perform a change to the datamodel, a local Migration file will be created and Jen pushes first. Bob doesn't pay too much attention what code Jen already pushed, just pulls and as he doesn't get any conflict, also pushes his code:

Jen's new `0002-1548425150000.ts`:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createField({
    model: 'User',
    name: 'address',
    type: 'String',
    migrationValue: '',
  }),
])
```

Bob's new `0002-1548425140000.ts`

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createField({
    model: 'User',
    name: 'age',
    type: 'Int',
    migrationValue: -1,
  }),
])
```

After the merge, the filesystem will look like this:

```
.
├── datamodel.prisma
├── migrate
│   ├── 0001_1548425145186.ts
│   ├── 0002-1548425140000.ts
│   └── 0002-1548425150000.ts
└── prisma.yml

```

The resulting datamodel will look like this:

```graphql
type User {
  id: ID! @id
  name: String!
  address: String!
  age: Int!
}
```

Prisma at this point should warn in a CI step, that two migrations have been created with the same version. But as these migrations are compatible, Prisma is able to merge them.

## Scenario 2: Two incompatible changes at the same time

Let's assume Jen now removes the `name` field from the `User` type, but Bob just wants to make it optional. This is a change that can't be solved automatically - we have a merge conflict.

The first barrier to prevent this from happening is a Git-based merge conflict in the `prisma.datamodel` file:

Jen's `datamodel.prisma` will look like this:

```graphql
type User {
  id: ID! @id
}
```

While Bob's `datamodel.prisma` will look like this:

```graphql
type User {
  id: ID @id
  name: String
}
```

The next barrier to catch this conflict is the actual Prisma migration system.

When the `prisma apply-migration` command is being executed in CI, it will read all migration files.

As soon as it will see the following two migrations, it will recognize a conflict:

Jen's migration file:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.deleteField({
    model: 'User',
    name: 'name',
  }),
])
```

Bob's migration file:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.updateField({
    model: 'User',
    name: 'name',
    type: 'String',
    isRequired: false,
  }),
])
```

Prisma would fail in this case and ask for manual resolution from the user.

## Scenario 3: Async Workflows, migrating data

In order to introduce a required field, that we need to initialize with proper data, we can provide a hook point for users to execute data transformations:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createField({
    model: 'User',
    name: 'address',
    type: 'String',
    isRequired: false,
  }),
  m.execute(async ctx => {
    for (const user of ctx.client.users().$stream()) {
      await ctx.client.updateUser(user.id, {
        address: 'some default address in the universe ' + Math.random(),
      })
    }
  }),
  m.updateField({
    model: 'User',
    name: 'address',
    type: 'String',
    isRequired: true,
  }),
])
```

The client could potentially even be typed with the new field. Note, that this requires a temporary endpoint, which already includes the new field, even if the migration is not yet done.

## Scenario 4: SQL / Database native code

To allow manipulating the underlying database directly, we provide a SQL interface:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [m.runSql(`CREATE TABLE X`, `DROP TABLE X`), m.runSql(`CREATE TABLE Y`)])
```

## Scenario 5: MongoDB access

The underlying MongoDB database could be manipulated like this:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.runMongo(
    [
      {
        createIndexes: 'mycollection',
        indexes: [
          {
            key: {
              username: 1,
              created: -1,
            },
            name: 'username_sort_by_asc_created',
            background: true,
          },
          {
            key: {
              email: 1,
            },
            name: 'unique_email',
            unique: true,
            background: true,
          },
        ],
      },
    ],
    [
      {
        dropIndexes: 'mycollection',
        index: 'username_sort_by_asc_created',
      },
      {
        dropIndexes: 'mycollection',
        index: 'unique_email',
      },
    ],
  ),
])
```

## Migration Operations

These are the possible operations, which the language specific migration definitions (like TypeScript or Go) will generate:

https://gist.github.com/mavilein/5b4a7407a4dfde9c070d26f276b0aa13

# Drawbacks

We could provide a completely free JavaScript API, without forcing the user to provide an array of operations. However, this wouldn't allow us to check migrations for validity upfront, so Prisma can't provide any guarantees and users would easily get into incosistent states with their database.

# Alternatives

# Adoption strategy

Users that are running the existing Prisma system will need to run `prisma migrate` instead of `prisma deploy`.
To opt into the file-based migrations, a single `prisma migrate generate` is sufficient.

# How we teach this

# Unresolved questions

## How do we handle big migrations that need to scale over millions of table entries?

This would require a more sophisticated migration system, that uses data syncing with a Ghost table, as implemented by https://github.com/github/gh-ost.

A potential API to handle these "online" changes in a big production system could look like this:

```ts
import { migrate } from 'prisma-sdk'

export default migrate(m => [
  m.createField({
    model: 'User',
    name: 'address',
    type: 'String',
    isRequired: true,
    migrationValue: '',
  }),
  m.runAsync({
    watch: {
      BeforeUserCreated: user => {
        const [firstName, lastName] = user.name.split(' ')
        user.firstName = firstName
        user.last = lastName
        return user
      },
    },
    run: async client => {
      for await (const user of client.users().$stream()) {
        await client.updateUser(user.id, 'BeforeUserCreated')
      }
    },
  }),
  m.updateField({
    model: 'User',
    name: 'address',
    type: 'String',
    isRequired: true,
  }),
])
```

## Should we block the API during migration?

Systems like Rails follow this approach. This would make migrations easier to reason about and prevent inconsistent data state. For a big production application this would however not be acceptable.

## Other

- [ ] How to generate a (type-safe) client for the run commands?
- [ ] Evaluate `dependsOn` concept
- [ ] Add option to prevent breaking changes
